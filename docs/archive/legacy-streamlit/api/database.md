# API Documentation - Database Handler

## SupabaseDataHandler

Primary database handler cho PostgreSQL database thÃ´ng qua Supabase.

### Class Overview

```python
class SupabaseDataHandler:
    """
    Optimized Supabase PostgreSQL data handler vá»›i robust initialization
    
    Attributes:
        engine: SQLAlchemy engine instance
        connected: bool - Connection status
        connection_info: dict - Connection metadata
        version_info: dict - Database version info
    """
```

---

## Constructor & Connection Management

### `__init__(self)`

**Description**: Khá»Ÿi táº¡o data handler vá»›i lazy connection.

**Process Flow**:
1. Initialize engine (khÃ´ng connect ngay)
2. Parse database URL tá»« secrets/env
3. Thá»±c hiá»‡n lightweight connection check
4. Táº¡o tables náº¿u cáº§n thiáº¿t

**Example**:
```python
data_handler = SupabaseDataHandler()
if data_handler.connected:
    print("âœ… Database connected successfully")
else:
    print("âŒ Database connection failed")
```

### `_init_engine(self)`

**Description**: Khá»Ÿi táº¡o SQLAlchemy engine vá»›i connection pooling.

**Configuration**:
```python
self.engine = create_engine(
    db_url,
    pool_pre_ping=True,
    connect_args={
        "sslmode": "require",
        "connect_timeout": 5
    }
)
```

### `_connect(self) -> bool`

**Description**: Test database connection vá»›i lightweight query.

**Returns**: 
- `bool`: True náº¿u connection thÃ nh cÃ´ng

**Test Query**: `SELECT 1` - minimal overhead

---

## Table Management

### `_create_tables(self)`

**Description**: Táº¡o táº¥t cáº£ tables cáº§n thiáº¿t náº¿u chÆ°a tá»“n táº¡i.

**Tables Created**:

#### Investors Table
```sql
CREATE TABLE IF NOT EXISTS investors (
    id INTEGER PRIMARY KEY,
    name VARCHAR(255) NOT NULL,
    phone VARCHAR(20),
    address TEXT,
    email VARCHAR(255),
    join_date DATE NOT NULL,
    is_fund_manager BOOLEAN DEFAULT FALSE
);
```

#### Tranches Table  
```sql
CREATE TABLE IF NOT EXISTS tranches (
    investor_id INTEGER,
    tranche_id VARCHAR(50) PRIMARY KEY,
    entry_date TIMESTAMP NOT NULL,
    entry_nav DECIMAL(15,6) NOT NULL,
    units DECIMAL(15,6) NOT NULL,
    original_invested_value DECIMAL(15,2) NOT NULL,
    hwm DECIMAL(15,6),
    original_entry_date TIMESTAMP,
    original_entry_nav DECIMAL(15,6),
    cumulative_fees_paid DECIMAL(15,2) DEFAULT 0,
    FOREIGN KEY (investor_id) REFERENCES investors(id)
);
```

#### Transactions Table
```sql
CREATE TABLE IF NOT EXISTS transactions (
    id SERIAL PRIMARY KEY,
    investor_id INTEGER NOT NULL,
    transaction_type VARCHAR(20) NOT NULL,
    amount DECIMAL(15,2) NOT NULL,
    transaction_date TIMESTAMP NOT NULL,
    nav_after_transaction DECIMAL(15,6) NOT NULL,
    units_change DECIMAL(15,6) NOT NULL,
    price_per_unit DECIMAL(15,6) NOT NULL,
    notes TEXT,
    FOREIGN KEY (investor_id) REFERENCES investors(id)
);
```

#### Fee Records Table
```sql
CREATE TABLE IF NOT EXISTS fee_records (
    id SERIAL PRIMARY KEY,
    investor_id INTEGER NOT NULL,
    fee_period VARCHAR(10) NOT NULL,
    fee_amount DECIMAL(15,2) NOT NULL,
    units_transferred DECIMAL(15,6) NOT NULL,
    calculated_date TIMESTAMP NOT NULL,
    nav_at_calculation DECIMAL(15,6) NOT NULL,
    performance_percentage DECIMAL(10,6),
    FOREIGN KEY (investor_id) REFERENCES investors(id)
);
```

---

## CRUD Operations - Investors

### `load_investors(self) -> List[Investor]`

**Description**: Load táº¥t cáº£ investors tá»« database.

**Returns**: 
- `List[Investor]`: Danh sÃ¡ch investors

**SQL Query**:
```sql
SELECT * FROM investors ORDER BY id
```

**Example**:
```python
investors = data_handler.load_investors()
print(f"Loaded {len(investors)} investors")
```

### `save_investors(self, investors: List[Investor]) -> bool`

**Description**: LÆ°u danh sÃ¡ch investors vá» database.

**Parameters**:
- `investors` (List[Investor]): Danh sÃ¡ch Ä‘á»ƒ lÆ°u

**Returns**: 
- `bool`: True náº¿u thÃ nh cÃ´ng

**Process**:
1. Begin transaction
2. Delete existing investors
3. Bulk insert new investors
4. Commit hoáº·c rollback

**Example**:
```python
success = data_handler.save_investors(investors)
if not success:
    st.error("Failed to save investors")
```

---

## CRUD Operations - Tranches

### `load_tranches(self) -> List[Tranche]`

**Description**: Load táº¥t cáº£ tranches tá»« database.

**Returns**: 
- `List[Tranche]`: Danh sÃ¡ch tranches

**SQL Query**:
```sql
SELECT * FROM tranches ORDER BY investor_id, entry_date
```

### `save_tranches(self, tranches: List[Tranche]) -> bool`

**Description**: LÆ°u danh sÃ¡ch tranches vá» database.

**Business Logic**:
- Replace toÃ n bá»™ table vá»›i data má»›i
- Maintain foreign key integrity
- Handle decimal precision cho financial data

---

## CRUD Operations - Transactions

### `load_transactions(self) -> List[Transaction]`

**Description**: Load táº¥t cáº£ transactions tá»« database.

**Returns**: 
- `List[Transaction]`: Danh sÃ¡ch transactions theo thá»© tá»± chronological

**SQL Query**:
```sql
SELECT * FROM transactions ORDER BY transaction_date DESC
```

### `save_transactions(self, transactions: List[Transaction]) -> bool`

**Description**: LÆ°u danh sÃ¡ch transactions vá» database.

**Auto-increment Handling**:
```python
# Handle auto-increment ID cho new transactions
next_id = 1
for transaction in transactions:
    if transaction.id is None:
        transaction.id = next_id
        next_id += 1
```

---

## CRUD Operations - Fee Records

### `load_fee_records(self) -> List[FeeRecord]`

**Description**: Load táº¥t cáº£ fee records tá»« database.

**Returns**: 
- `List[FeeRecord]`: Danh sÃ¡ch fee records

**SQL Query**:
```sql
SELECT * FROM fee_records ORDER BY calculated_date DESC
```

### `save_fee_records(self, fee_records: List[FeeRecord]) -> bool`

**Description**: LÆ°u danh sÃ¡ch fee records vá» database.

**Note**: Fee records thÆ°á»ng chá»‰ Ä‘Æ°á»£c thÃªm, khÃ´ng edit/delete.

---

## Batch Operations

### `save_all_data_enhanced(self, investors, tranches, transactions, fee_records) -> bool`

**Description**: LÆ°u táº¥t cáº£ data trong má»™t transaction duy nháº¥t.

**Parameters**:
- `investors` (List[Investor])
- `tranches` (List[Tranche]) 
- `transactions` (List[Transaction])
- `fee_records` (List[FeeRecord])

**Returns**: 
- `bool`: True náº¿u táº¥t cáº£ operations thÃ nh cÃ´ng

**Transaction Flow**:
```python
def save_all_data_enhanced(self, investors, tranches, transactions, fee_records):
    try:
        with self.engine.begin() as conn:
            # Save investors first (parent table)
            self._save_investors_batch(conn, investors)
            
            # Save dependent tables
            self._save_tranches_batch(conn, tranches)
            self._save_transactions_batch(conn, transactions)
            self._save_fee_records_batch(conn, fee_records)
            
            # All operations committed together
            return True
    except Exception as e:
        # Automatic rollback on any error
        return False
```

**Benefits**:
- ACID compliance
- All-or-nothing persistence
- Better performance than individual saves
- Referential integrity maintained

---

## Utility Methods

### `test_connection(self) -> bool`

**Description**: Test database connectivity.

**Usage**: Health checks vÃ  debugging

### `get_connection_info(self) -> dict`

**Description**: Láº¥y thÃ´ng tin connection Ä‘á»ƒ display.

**Returns**:
```python
{
    "host": "hostname",
    "port": 5432,
    "database": "database_name",
    "user": "username",
    "status": "connected"
}
```

### `_parse_db_url(self, db_url: str) -> dict`

**Description**: Parse DATABASE_URL thÃ nh components.

**Example**:
```python
# Input: "postgresql://user:pass@host:5432/dbname"
# Output: {"host": "host", "port": 5432, "database": "dbname", "user": "user"}
```

---

## Error Handling

### Connection Errors

```python
try:
    data_handler = SupabaseDataHandler()
except Exception as e:
    st.error(f"Database initialization failed: {e}")
    # Fallback to CSV handler
    from data_handler import EnhancedDataHandler
    data_handler = EnhancedDataHandler()
```

### Query Errors

```python
def load_investors(self):
    try:
        with self.engine.connect() as conn:
            result = conn.execute(text("SELECT * FROM investors"))
            return [self._row_to_investor(row) for row in result]
    except Exception as e:
        st.error(f"Failed to load investors: {e}")
        return []  # Return empty list to prevent app crash
```

### Transaction Rollback

```python
def save_all_data_enhanced(self, ...):
    try:
        with self.engine.begin() as conn:  # Auto-rollback on exception
            # All database operations
            pass
    except Exception as e:
        # Automatic rollback happened
        st.error(f"Failed to save data: {e}")
        return False
```

---

## Performance Optimizations

### Connection Pooling

```python
# Engine configuration cho optimal performance
create_engine(
    database_url,
    pool_size=10,           # Connections trong pool
    max_overflow=20,        # Additional connections khi cáº§n
    pool_timeout=30,        # Timeout chá» connection
    pool_recycle=3600,      # Recycle connections má»—i 1h
    pool_pre_ping=True      # Validate connections trÆ°á»›c dÃ¹ng
)
```

### Bulk Operations

```python
def _save_investors_batch(self, conn, investors):
    """Bulk insert thay vÃ¬ individual INSERTs"""
    
    # Prepare data
    investor_data = [
        {
            'id': inv.id,
            'name': inv.name,
            'phone': inv.phone,
            'address': inv.address,
            'email': inv.email,
            'join_date': inv.join_date,
            'is_fund_manager': inv.is_fund_manager
        }
        for inv in investors
    ]
    
    # Bulk insert - much faster than individual INSERTs
    conn.execute(
        text("INSERT INTO investors (id, name, phone, address, email, join_date, is_fund_manager) "
             "VALUES (:id, :name, :phone, :address, :email, :join_date, :is_fund_manager)"),
        investor_data
    )
```

### Query Optimization

```python
# Sá»­ dá»¥ng indexes
def create_indexes(self):
    """Create indexes cho performance"""
    with self.engine.begin() as conn:
        # Index cho foreign keys
        conn.execute(text("CREATE INDEX IF NOT EXISTS idx_tranches_investor_id ON tranches(investor_id)"))
        conn.execute(text("CREATE INDEX IF NOT EXISTS idx_transactions_investor_id ON transactions(investor_id)"))
        conn.execute(text("CREATE INDEX IF NOT EXISTS idx_fee_records_investor_id ON fee_records(investor_id)"))
        
        # Index cho date queries
        conn.execute(text("CREATE INDEX IF NOT EXISTS idx_transactions_date ON transactions(transaction_date)"))
        conn.execute(text("CREATE INDEX IF NOT EXISTS idx_fee_records_date ON fee_records(calculated_date)"))
```

---

## Backup & Recovery

### Database Backup

```python
def backup_database(self, backup_file: str) -> bool:
    """Create database backup"""
    try:
        import subprocess
        db_url = os.getenv("DATABASE_URL")
        
        # Use pg_dump for PostgreSQL backup
        result = subprocess.run([
            "pg_dump", 
            db_url,
            "-f", backup_file
        ], capture_output=True, text=True)
        
        return result.returncode == 0
    except Exception as e:
        st.error(f"Backup failed: {e}")
        return False
```

### Data Export

```python
def export_to_csv(self, table_name: str, output_file: str) -> bool:
    """Export table to CSV for backup"""
    try:
        query = f"SELECT * FROM {table_name}"
        df = pd.read_sql(query, self.engine)
        df.to_csv(output_file, index=False)
        return True
    except Exception as e:
        st.error(f"Export failed: {e}")
        return False
```

---

## Migration Support

### Schema Migrations

```python
def migrate_database(self, target_version: int) -> bool:
    """Run database migrations to target version"""
    current_version = self._get_schema_version()
    
    if current_version < target_version:
        for version in range(current_version + 1, target_version + 1):
            if not self._run_migration(version):
                return False
    
    return True

def _run_migration(self, version: int) -> bool:
    """Run specific migration"""
    migration_sql = self._get_migration_sql(version)
    
    try:
        with self.engine.begin() as conn:
            conn.execute(text(migration_sql))
            conn.execute(text(f"UPDATE schema_version SET version = {version}"))
        return True
    except Exception as e:
        st.error(f"Migration {version} failed: {e}")
        return False
```

---

## Alternative Data Handler

### EnhancedDataHandler (CSV Fallback)

Khi Supabase khÃ´ng available, há»‡ thá»‘ng tá»± Ä‘á»™ng fallback vá» CSV storage:

```python
class EnhancedDataHandler:
    """Fallback CSV data handler"""
    
    def __init__(self, backup_dir="backups"):
        self.backup_dir = Path(backup_dir)
        self.backup_dir.mkdir(exist_ok=True)
        self.connected = True  # CSV luÃ´n "connected"
    
    def load_investors(self) -> List[Investor]:
        """Load tá»« investors.csv"""
        csv_file = self.backup_dir / "investors.csv"
        if csv_file.exists():
            df = pd.read_csv(csv_file)
            return [self._row_to_investor(row) for _, row in df.iterrows()]
        return []
    
    def save_investors(self, investors: List[Investor]) -> bool:
        """Save to investors.csv"""
        try:
            df = pd.DataFrame([asdict(inv) for inv in investors])
            df.to_csv(self.backup_dir / "investors.csv", index=False)
            return True
        except Exception:
            return False
```

**Usage**:
```python
# Automatic fallback trong app.py
@st.cache_resource
def load_data_handler():
    try:
        data_handler = SupabaseDataHandler()
        if data_handler.connected:
            return data_handler
    except:
        pass
    
    # Fallback to CSV
    st.warning("ðŸ“„ Using CSV storage (database unavailable)")
    return EnhancedDataHandler()
```